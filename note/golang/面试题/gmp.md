gmp调度器：g是goruntine，m是线程，p是调度器

一、现状

并发场景每个线程的会拥有一段时间cpu，cpu时间浪费成本在于线程切换，内核态与用户态切换
解决方案：将线程分为内核态线程，用户态线程，也就是协程；让协程绑定线程，并发场景就是在用户态切换，这种切换非常轻量

这种方案需要解决：多线程与多协程的绑定，切换运行协程

二、GMP模型

1. runtime.main会创建一个m0，它会初始化多个调度器并创建相应的本地队列，用于存放要在p上调度的goruntine，创建一个全局队列；
2. m0会创建g0,用于调度goruntine运行；完成所有初始化工作会变成普通的m，绑定一个调度器
3. 当goruntine创建后，会移动到本地队列；如果本地队列满了，会将本地队列前一半的g打乱顺序加入全局队列
4. 当m空闲，其g0会调度p其上的本地队列的g，先进先出，运行g
4.1 如果本地队列空闲，会从全局队列获取一批g（n = min(len(GQ)/GOMAXPROCS + 1, len(GQ/2))）
4.2 如果全局队列也是空的，会从其他队列偷取一半的g
4.3 如果都没有g，m会自旋，系统最多有GoMaxProc数量的m自旋，其他m会休眠
5. m运行g，如果阻塞或者syscall，会将m从p上摘除；创建新的线程（或者获取一个空闲线程）来服务p
6. 当m调用结束（时间片用完），m会尝试获得p，如果没有p，m会进入休眠状态，将g放到全局队列中


三、调度器的设计策略

1. 复用线程
1.1 wark stealing机制：当线程没有可以工作的g，会尝试从其他队列偷取g
1.2 hand off机制：当线程进行系统调用阻塞时，会与p解绑，将p给其他空闲线程
2. 利用并行：GOMAXPROC设置调度器最大数量，可以分布在多核cpu运行
3. 抢占：一个goruntine最大占用cpu 10ms，防止其他goruntine饿死（go 1.14的异步式抢占，会启动sysmon线程监控其他线程，当其他线程goruntine执行超过10ms,会发送一个抢占信号量，中断协程执行）
4. 全局g队列：让线程可以从全局队列获取g


四、g,m,p数量
1. g的数量：g数量受cpu，内存，linux文件描述符限制，goroutine栈大小是2-4kb，2g内存也就是数十万个，但同时也看g中执行的程序，如打开文件，io等，还受linux本身文件描述符数量限制
2. p的数量，在runtime的GoMaxProc函数影响，默认是cpu核数，如果是io密集型可以调大;在云上获得的核数是宿主机的核数，实际pod的cpu资源是受限的，造成p数量较大，可以适当调小或者引入uber的automaxprocs包
2.1 为什么io密集型调大p数量性能会更好？因为io密集型会造成m阻塞，但是go调度器本身为了减少对m的干预，会隔一段时间才去检测m阻塞，也就不会立马把m绑定的p抢走，如果p和核数相同，cpu资源就浪费了
3. m的数量，首先受runtime的gomaxmcount限制，最大是一万，还受到runtime.SetMaxThreads函数配置，如果没有配置，一般一个p创建一个m，如果m阻塞导致p解绑会额外创建新的m，也就算m的数量会大于等于p